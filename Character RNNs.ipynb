{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640c0522",
   "metadata": {},
   "source": [
    "# Character-level RNNs for generating contract clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0222f8",
   "metadata": {},
   "source": [
    "# To Do & Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40959e2f",
   "metadata": {},
   "source": [
    "- [ ] Mechanics of model training\n",
    "    - Inspect weights to make sure they're changing.\n",
    "    - Does the prediction get more correct on each iteration?\n",
    "\n",
    "- [ ] Expand from dev vocab to full ASCII alphabet\n",
    "- [ ] From single examples to batch\n",
    "- [ ] How reset the hidden state on a new \"run\" (whatever that means), without resetting the learned weights too?\n",
    "- [ ] How to process a single call to `model.forward` as a sequence, instead of one character at a time?\n",
    "- [ ] How is the PyTorch RNN layer implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0f2d1",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1192623",
   "metadata": {},
   "source": [
    "* The model seems to get stuck in absorbing states. Repeating the call to `generate_text` yields the same output - why would that be? First guess is a bug. If not, though, then what?\n",
    "    - Suggests a deeper thing about UI: model should have a public `reset_state` method that sets state back to 0 (but doesn't change the weights at all)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b871d45",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9890fe",
   "metadata": {},
   "source": [
    "**Goal:** reproduce Karpathy's blog post on character RNNs for Paul Graham essays and Shakespeare, to really grok \n",
    "how RNNs work deeply.\n",
    "\n",
    "https://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe3d84",
   "metadata": {},
   "source": [
    "\n",
    "## Pieces from the blog post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f159be",
   "metadata": {},
   "source": [
    "* Train vs. evaluate\n",
    "* Use validation set during training\n",
    "* Watch how quality evolves over training epochs\n",
    "* RNN state updates vs. LSTM state updates\n",
    "* Stacking RNNs\n",
    "* Dropout\n",
    "* Backprop through time (BPTT)?\n",
    "* Visualize next-char distribution, given input sequence\n",
    "* Visualize key active neurons, given an input sequence. Any that are immediately interpretable.\n",
    "* Optimizer: RMSProp or Adam\n",
    "* Temperature of sampling\n",
    "* Sampling logic (beam search, vs. one letter at a time?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55f05f",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a05f5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"lex_glue\", \"ledgar\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717566f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chars(corpus: list[str]):\n",
    "    return sum(map(len, corpus))\n",
    "\n",
    "def pprint(x: int):\n",
    "    print(f\"{x:_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35efe7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42_460_532\n"
     ]
    }
   ],
   "source": [
    "pprint(count_chars(ds['train']['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a54d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_995_963\n"
     ]
    }
   ],
   "source": [
    "pprint(count_chars(ds['validation']['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8420d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_698_900\n"
     ]
    }
   ],
   "source": [
    "pprint(count_chars(ds['test']['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166eb1b",
   "metadata": {},
   "source": [
    "# Tiny data for dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105791b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Except as otherwise set forth in this Debenture, the Company, for itself and its legal representatives, successors and assigns, expressly waives presentment, protest, demand, notice of dishonor, notice of nonpayment, notice of maturity, notice of protest, presentment for the purpose of accelerating maturity, and diligence in collection.',\n",
       " 'No ERISA Event has occurred or is reasonably expected to occur that, when taken together with all other such ERISA Events for which liability is reasonably expected to occur, could reasonably be expected to result in a Material Adverse Effect. Neither Borrower nor any ERISA Affiliate maintains or contributes to or has any obligation to maintain or contribute to any Multiemployer Plan or Plan, nor otherwise has any liability under Title IV of ERISA.',\n",
       " 'This Amendment may be executed by one or more of the parties hereto on any number of separate counterparts, and all of said counterparts taken together shall be deemed to constitute one and the same instrument. This Amendment may be delivered by facsimile or other electronic transmission of the relevant signature pages hereof.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ds['train']['text'][:3]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d965f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_118\n"
     ]
    }
   ],
   "source": [
    "pprint(count_chars(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa89981",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76383ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1b4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 's', 't', 'l', 'n', 'e', 'a', '.', ' ', '<UNK>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = \"rstlnea\" + \".\" + \" \"\n",
    "vocab = list(vocab) + ['<UNK>']\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d2464e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0,\n",
       " 's': 1,\n",
       " 't': 2,\n",
       " 'l': 3,\n",
       " 'n': 4,\n",
       " 'e': 5,\n",
       " 'a': 6,\n",
       " '.': 7,\n",
       " ' ': 8,\n",
       " '<UNK>': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2ix = {c: i for i, c in enumerate(vocab)}\n",
    "# char2ix['<UNK>'] = len(char2ix)\n",
    "char2ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4c298",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e941674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbc0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, vocab_length, hidden_units):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = vocab_length\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.eye(vocab_length))  # frozen by default\n",
    "        self.h = torch.zeros(hidden_units)\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_units, hidden_units))\n",
    "        self.W_hx = nn.Parameter(torch.randn(hidden_units, self.embedding_dim))\n",
    "        self.W_out = nn.Parameter(torch.randn(vocab_length, hidden_units))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.h = torch.tanh(self.W_hh @ self.h + self.W_hx @ self.embedding(x)[0])\n",
    "        y = self.W_out @ self.h\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6067e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyRNN(\n",
       "  (embedding): Embedding(10, 10)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyRNN(vocab_length=len(vocab), hidden_units=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e7a89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.1697,  0.1895, -0.3283,  1.8748],\n",
       "         [-0.7445, -0.6746, -1.1363, -0.3717],\n",
       "         [ 0.7787, -1.6314, -0.4668, -0.9429],\n",
       "         [ 1.1840, -2.0334,  0.5015, -1.1130]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.5139,  0.8695,  1.1172, -0.4834,  2.2298,  1.6107, -0.1146,  1.0463,\n",
       "           3.0711,  0.4728],\n",
       "         [ 0.3356,  1.0531, -0.3292,  0.6214, -0.3036,  0.3481, -1.5734, -2.1714,\n",
       "          -1.7093, -0.6690],\n",
       "         [ 0.4458, -1.8069, -1.1456, -1.1808,  0.5067, -0.1222,  0.2413, -0.7415,\n",
       "          -0.7576, -0.8985],\n",
       "         [-1.2563, -0.9955,  1.3200, -0.1624, -1.9447, -0.4463,  1.8253,  0.4621,\n",
       "           0.1607,  0.6085]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.6856, -0.2899,  0.6719,  0.0141],\n",
       "         [-0.0730, -0.0859, -1.0558,  0.3905],\n",
       "         [ 0.2735, -1.0138,  0.6939,  0.6311],\n",
       "         [-0.8066, -0.7271, -0.0401,  0.3221],\n",
       "         [ 1.4747, -0.5686,  0.3175, -0.1307],\n",
       "         [-3.2276,  1.7267, -0.7137, -0.7019],\n",
       "         [ 0.3279,  0.6460, -1.4127,  0.5326],\n",
       "         [-2.3454,  0.3049, -1.9256,  1.7199],\n",
       "         [-0.5313, -1.4727, -0.7213,  1.2915],\n",
       "         [-0.1225, -0.8432, -0.3871,  0.6810]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04fc46",
   "metadata": {},
   "source": [
    "# Demo model `step` interface with changing internal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.tensor([5])\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43527f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17038d62",
   "metadata": {},
   "source": [
    "# Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char2ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c647ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective(input=y, target=torch.tensor(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2e382",
   "metadata": {},
   "source": [
    "# Sample from the (untrained) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af46c0",
   "metadata": {},
   "source": [
    "For now, just take the most probable output from the model. Later can work on sampling, temperature, beam search, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb6d3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_prompt(model, prompt: str):\n",
    "    \"\"\"Update the model's hidden state based on a user prompt. The model is mutated, not returned.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    for c in prompt:\n",
    "        x = torch.tensor([char2ix[c]])\n",
    "        with torch.no_grad():\n",
    "            y = model(x)\n",
    "        ix = torch.argmax(y, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af778987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyRNN(\n",
       "  (embedding): Embedding(10, 10)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyRNN(vocab_length=len(vocab), hidden_units=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73d59c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bb232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prompt(model, \"nearest \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "300c242d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6279,  0.5244, -0.4616,  0.4919])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90c6632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregress(model, start_char: str, num_chars: int) -> str:\n",
    "    model.eval()\n",
    "    out = ''\n",
    "    \n",
    "    ix = torch.tensor([char2ix[start_char]])\n",
    "    \n",
    "    for _ in range(num_chars):\n",
    "        with torch.no_grad():\n",
    "            y = model(ix)\n",
    "        ix = torch.argmax(y, keepdim=True)\n",
    "        out += vocab[ix]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c9d37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prompt, num_chars):\n",
    "    # Run model forward on the prompt to set hidden state.\n",
    "    set_prompt(model, prompt)\n",
    "    \n",
    "    # Generate new text, auto-regressive style.\n",
    "    out = autoregress(model, start_char=prompt[-1], num_chars=num_chars)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a524669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyRNN(\n",
       "  (embedding): Embedding(10, 10)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyRNN(vocab_length=len(vocab), hidden_units=4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac5e2246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sllenelenelenelenelenelenelenelenelenelenelenelene'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, prompt=\"nearest \", num_chars=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2c96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
